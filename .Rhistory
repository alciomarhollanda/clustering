cons.funs = c("majority"))
knitr::kable(head(obj$clusters))
obj <- dice(dat, nk = 3, reps = 10, algorithms = c("km","hc","diana"),
cons.funs = c("majority"))
knitr::kable(head(obj$clusters))
head(obj$clusters)
obj$clusters
obj
knitr::kable(obj$indices$ii$`3`)
x <- consensus_cluster(dat, nk = 3, reps = 10, algorithms = c("km","hc","diana"),
progress = FALSE)
x
km.3 <- x[, , "KM_Euclidean", "3", drop = FALSE]
cm <- consensus_matrix(km.3)
dim(cm)
hm <- graph_heatmap(km.3)
km.3
head(km.3)
km.3
x
km.3 <- x[, , "HC_Euclidean", "3", drop = FALSE]
cm <- consensus_matrix(km.3)
dim(cm)
hm <- graph_heatmap(km.3)
ccomb_matrix <- consensus_combine(x, element = "matrix")
ccomb_matrix
ccomb_class <- consensus_combine(x, element = "class")
ccomb_class
str(ccomb_matrix, max.level = 2)
str(ccomb_matrix, max.level = 3)
str(ccomb_matrix, max.level = 2)
cm_k3 <- consensus_matrix(ccomb_class$`3`)
cm_k3
ccomp <- consensus_evaluate(hgsc, x, plot = FALSE)
ccomp <- consensus_evaluate(dat, x, plot = FALSE)
ccomp
ccomp <- consensus_evaluate(dat, x, plot = TRUE)
ccomp <- consensus_evaluate(dat, x, plot = TRUE)
cm_k3
table(cm_k3, iris$Species)
mvData
cm_k3$cluster
x
x$cluster
ccomb_class
cm_k3
ccomb_class2 <- consensus_combine(cm_k3, element = "class")
cm_k3
ccomb_class2 <- consensus_combine(ccomb_class$`3`, element = "class")
cm_k3 <- consensus_matrix(ccomb_class$`3`)
cm_k3
ccomb_class
cm_k3 <- consensus_matrix(ccomb_class)
cm_k3
ccomb_class <- consensus_combine(x, element = "class")
ccomb_class
library(diceR)
library(dplyr)
library(ggplot2)
library(diceR)
library(dplyr)
library(ggplot2)
library(pander)
data(hgsc)
hgsc <- hgsc[1:100, 1:50]
#agrupar os hgscdados em 3 ou 4 clusters, usando 80% de reimampling em 5 repeti??es,
#para esses algoritmos de cluster: Hierarchical Clustering, PAM e DIvisive
#ANAlysis Clustering (DIANA).
#A dist?ncia euclidiana ? utilizada para todos os algoritmos.
CC <- consensus_cluster(hgsc, nk = 3:4, p.item = 0.8, reps = 5,
algorithms = c("hc", "pam", "diana"))
co <- capture.output(str(CC))
strwrap(co, width = 80)
CC <- apply(CC, 2:4, impute_knn, data = hgsc, seed = 1)
bigger = options()$max.print  # or add something larger
options("max.print" = bigger) # apparently RStudio sets max.print very low.
CC
# Filtra somente PAM_Euclidean 4
pam.4 <- CC[, , "PAM_Euclidean", "4", drop = FALSE]
cm <- consensus_matrix(pam.4)
dim(cm)
dev.off()
hm <- graph_heatmap(pam.4)
dev.off()
ccomb_matrix <- consensus_combine(CC, element = "matrix")
ccomb_class <- consensus_combine(CC, element = "class")
ccomb_matrix
ccomb_class
str(ccomb_matrix, max.level  = 5)
cm_k3 <- consensus_matrix(ccomb_class$`3`)
cm_k3
cm_k4 <- consensus_matrix(ccomb_class$`4`)
x <- consensus_cluster(dat, nk = 3, reps = 10, algorithms = c("km","hc","diana"),
progress = FALSE)
library(diceR)
library(ggplot2)
dat <- iris[, -5]
head(iris)
head(dat)
x <- consensus_cluster(dat, nk = 3, reps = 10, algorithms = c("km"),
progress = FALSE)
x <- consensus_cluster(dat, nk = 3, reps = 10, algorithms = c("km","hc","diana"),
progress = FALSE)
ccomp <- consensus_evaluate(dat, x, plot = TRUE)
x <- consensus_cluster(dat, nk = 3, reps = 10, algorithms = c("km","hc","diana"),
progress = FALSE, plot = TRUE )
x <- consensus_cluster(dat, nk = 3, reps = 10, algorithms = c("km","hc","diana"),
progress = FALSE, plot(progress=TRUE) )
x <- consensus_cluster(dat, nk = 3, reps = 10, algorithms = c("km","hc","diana"),
progress = FALSE )
km.3 <- CC[, , "KM_Euclidean", "3", drop = FALSE]
km.3 <- x[, , "KM_Euclidean", "3", drop = FALSE]
cm <- consensus_matrix(km.3)
dim(cm)
hm <- graph_heatmap(km.3)
km.3 <- x[, , "HC_Euclidean", "3", drop = FALSE]
cm <- consensus_matrix(km.3)
dim(cm)
cm
hm <- graph_heatmap(km.3)
km.3 <- x[, , "HC_Euclidean", "3", drop = FALSE]
cm <- consensus_matrix(km.3)
dim(cm)
hm <- graph_heatmap(km.3)
ccomp <- consensus_evaluate(dat, x, plot = TRUE)
ccomp <- consensus_evaluate(dat, x, plot = TRUE)
x <- consensus_cluster(dat, nk = 3, reps = 5, algorithms = c("km","hc","diana"),
progress = FALSE )
km.3 <- x[, , "HC_Euclidean", "3", drop = FALSE]
cm <- consensus_matrix(km.3)
dim(cm)
hm <- graph_heatmap(km.3)
ccomp <- consensus_evaluate(dat, x, plot = TRUE)
ccomp <- consensus_evaluate(dat, x, plot = TRUE)
ccomb_matrix <- consensus_combine(CC, element = "matrix")
ccomb_class <- consensus_combine(CC, element = "class")
ccomb_matrix <- consensus_combine(x, element = "matrix")
ccomb_class <- consensus_combine(x, element = "class")
hm <- graph_heatmap(ccomb_matrix)
hm <- graph_heatmap(ccomb_class)
ccomb_class
cm_all <- consensus_matrix(ccomb_class)
cm_all
hm <- graph_heatmap(cm_all)
cm_all
hm <- graph_heatmap(cm_all)
# Plot CDF
p <- graph_cdf(CC1)
data(hgsc)
dat <- hgsc[1:100, 1:50]
x <- consensus_cluster(dat, nk = 4, reps = 4, algorithms = c("hc", "diana"),
progress = FALSE)
CSPA(x, k = 4)
# Consensus clustering for 3 algorithms
library(ggplot2)
set.seed(911)
x <- matrix(rnorm(80), ncol = 10)
CC1 <- consensus_cluster(x, nk = 2:4, reps = 3,
algorithms = c("hc", "pam", "km"), progress = FALSE)
# Plot CDF
p <- graph_cdf(CC1)
# Plot CDF
p <- graph_cdf(CC1)
CC1
# Plot CDF
p <- graph_cdf(CC1)
# Change y label and add colours
p + labs(y = "Probability") + stat_ecdf(aes(colour = k)) +
scale_color_brewer(palette = "Set2")
library(diceR)
library(dplyr)
library(ggplot2)
library(pander)
data(hgsc)
hgsc <- hgsc[1:100, 1:50]
#agrupar os hgscdados em 3 ou 4 clusters, usando 80% de reimampling em 5 repeti??es,
#para esses algoritmos de cluster: Hierarchical Clustering, PAM e DIvisive
#ANAlysis Clustering (DIANA).
#A dist?ncia euclidiana ? utilizada para todos os algoritmos.
CC <- consensus_cluster(hgsc, nk = 3:4, p.item = 0.8, reps = 5,
algorithms = c("hc", "pam", "diana"))
co <- capture.output(str(CC))
strwrap(co, width = 80)
CC <- apply(CC, 2:4, impute_knn, data = hgsc, seed = 1)
bigger = options()$max.print  # or add something larger
options("max.print" = bigger) # apparently RStudio sets max.print very low.
CC
# Filtra somente PAM_Euclidean 4
pam.4 <- CC[, , "PAM_Euclidean", "4", drop = FALSE]
cm <- consensus_matrix(pam.4)
dim(cm)
dev.off()
hm <- graph_heatmap(pam.4)
ccomb_matrix <- consensus_combine(CC, element = "matrix")
ccomb_class <- consensus_combine(CC, element = "class")
str(ccomb_matrix, max.level  = 5)
cm_k3 <- consensus_matrix(ccomb_class$`3`)
cm_k4 <- consensus_matrix(ccomb_class$`4`)
# consensus matrix across subsamples and algorithms and k
cm_all <- consensus_matrix(ccomb_class)
CC2 <- consensus_cluster(hgsc, nk = 3:4, p.item = 0.8, reps = 5,
algorithms = "km")
ccomb_class2 <- consensus_combine(CC, CC2, element = "class")
ccomp <- consensus_evaluate(hgsc, CC, CC2, plot = FALSE)
ctrim <- consensus_evaluate(hgsc, CC, CC2, trim = TRUE, reweigh = FALSE, n = 2)
data(hgsc)
dat <- hgsc[1:100, 1:50]
x <- consensus_cluster(dat, nk = 4, reps = 4, algorithms = c("hc", "diana"),
progress = FALSE)
CSPA(x, k = 4)
# Consensus clustering for 3 algorithms
library(ggplot2)
set.seed(911)
x <- matrix(rnorm(80), ncol = 10)
CC1 <- consensus_cluster(x, nk = 2:4, reps = 3,
algorithms = c("hc", "pam", "km"), progress = FALSE)
# Plot CDF
p <- graph_cdf(CC1)
# Change y label and add colours
p + labs(y = "Probability") + stat_ecdf(aes(colour = k)) +
scale_color_brewer(palette = "Set2")
# Delta Area
p <- graph_delta_area(CC1)
# Heatmaps with column side colours corresponding to clusters
CC2 <- consensus_cluster(x, nk = 3, reps = 3, algorithms = "hc", progress =
FALSE)
graph_heatmap(CC2)
# Track how cluster assignments change between algorithms
p <- graph_tracking(CC1)
data(hgsc)
library(diceR)
library(dplyr)
library(ggplot2)
library(pander)
data(hgsc)
hgsc <- hgsc[1:100, 1:50]
#agrupar os hgscdados em 3 ou 4 clusters, usando 80% de reimampling em 5 repeti??es,
#para esses algoritmos de cluster: Hierarchical Clustering, PAM e DIvisive
#ANAlysis Clustering (DIANA).
#A dist?ncia euclidiana ? utilizada para todos os algoritmos.
CC <- consensus_cluster(hgsc, nk = 3:4, p.item = 0.8, reps = 5,
algorithms = c("hc", "pam", "diana"))
co <- capture.output(str(CC))
strwrap(co, width = 80)
CC <- apply(CC, 2:4, impute_knn, data = hgsc, seed = 1)
bigger = options()$max.print  # or add something larger
options("max.print" = bigger) # apparently RStudio sets max.print very low.
CC
# Filtra somente PAM_Euclidean 4
pam.4 <- CC[, , "PAM_Euclidean", "4", drop = FALSE]
cm <- consensus_matrix(pam.4)
dim(cm)
dev.off()
hm <- graph_heatmap(pam.4)
ccomb_matrix <- consensus_combine(CC, element = "matrix")
ccomb_class <- consensus_combine(CC, element = "class")
str(ccomb_matrix, max.level  = 5)
cm_k3 <- consensus_matrix(ccomb_class$`3`)
cm_k4 <- consensus_matrix(ccomb_class$`4`)
# consensus matrix across subsamples and algorithms and k
cm_all <- consensus_matrix(ccomb_class)
CC2 <- consensus_cluster(hgsc, nk = 3:4, p.item = 0.8, reps = 5,
algorithms = "km")
ccomb_class2 <- consensus_combine(CC, CC2, element = "class")
ccomp <- consensus_evaluate(hgsc, CC, CC2, plot = FALSE)
ctrim <- consensus_evaluate(hgsc, CC, CC2, trim = TRUE, reweigh = FALSE, n = 2)
data(hgsc)
dat <- hgsc[1:100, 1:50]
x <- consensus_cluster(dat, nk = 4, reps = 4, algorithms = c("hc", "diana"),
progress = FALSE)
CSPA(x, k = 4)
# Consensus clustering for 3 algorithms
library(ggplot2)
set.seed(911)
x <- matrix(rnorm(80), ncol = 10)
CC1 <- consensus_cluster(x, nk = 2:4, reps = 3,
algorithms = c("hc", "pam", "km"), progress = FALSE)
# Plot CDF
p <- graph_cdf(CC1)
CC1
# Consensus clustering for 3 algorithms
library(ggplot2)
set.seed(911)
x <- matrix(rnorm(80), ncol = 10)
CC1 <- consensus_cluster(x, nk = 2:4, reps = 3,
algorithms = c("hc", "pam", "km"), progress = FALSE)
# Plot CDF
p <- graph_cdf(CC1)
dev.off()
# Plot CDF
p <- graph_cdf(CC1)
CC1
# Change y label and add colours
p + labs(y = "Probability") + stat_ecdf(aes(colour = k)) +
scale_color_brewer(palette = "Set2")
# Plot CDF
p <- graph_cdf(CC1)
# Change y label and add colours
p + labs(y = "Probability") + stat_ecdf(aes(colour = k)) +
scale_color_brewer(palette = "Set2")
# Delta Area
p <- graph_delta_area(CC1)
dev.off()
# Plot CDF
p <- graph_cdf(CC1)
# Heatmaps with column side colours corresponding to clusters
CC2 <- consensus_cluster(x, nk = 3, reps = 3, algorithms = "hc", progress =
FALSE)
graph_heatmap(CC2)
# Track how cluster assignments change between algorithms
p <- graph_tracking(CC1)
dev.off()
# Track how cluster assignments change between algorithms
p <- graph_tracking(CC1)
table(majority_voting(cc[, , 1, 1, drop = FALSE], is.relabelled = FALSE))
data(hgsc)
dat <- hgsc[1:100, 1:50]
cc <- consensus_cluster(dat, nk = 4, reps = 6, algorithms = "pam", progress =
FALSE)
table(majority_voting(cc[, , 1, 1, drop = FALSE], is.relabelled = FALSE))
x <- consensus_cluster(dat, nk = 3, reps = 5, algorithms = c("km","hc","diana"),
progress = FALSE )
km.3 <- x[, , "HC_Euclidean", "3", drop = FALSE]
cm <- consensus_matrix(km.3)
dim(cm)
library(diceR)
library(ggplot2)
dat <- iris[, -5]
head(iris)
head(dat)
x <- consensus_cluster(dat, nk = 3, reps = 5, algorithms = c("km","hc","diana"),
progress = FALSE )
km.3 <- x[, , "HC_Euclidean", "3", drop = FALSE]
cm <- consensus_matrix(km.3)
dim(cm)
hm <- graph_heatmap(km.3)
ccomp <- consensus_evaluate(dat, x, plot = TRUE)
ccomb_matrix <- consensus_combine(x, element = "matrix")
ccomb_class <- consensus_combine(x, element = "class")
hm <- graph_heatmap(ccomb_class)
x <- consensus_cluster(dat, nk = 3, reps = 5, algorithms = c("km","hc","diana"),
progress = FALSE )
dev.off()
# Plot CDF
p <- graph_cdf(x)
# Change y label and add colours
p + labs(y = "Probability") + stat_ecdf(aes(colour = k)) +
scale_color_brewer(palette = "Set2")
# Delta Area
p <- graph_delta_area(x)
km.3 <- x[, , "HC_Euclidean", "3", drop = FALSE]
cm <- consensus_matrix(km.3)
dim(cm)
hm <- graph_heatmap(km.3)
cm_all
x <- consensus_cluster(dat, nk = 3, reps = 5, algorithms = c("km","hc","diana"),
progress = FALSE )
dev.off()
# Plot CDF
p <- graph_cdf(x)
# Change y label and add colours
p + labs(y = "Probability") + stat_ecdf(aes(colour = k)) +
scale_color_brewer(palette = "Set2")
# Delta Area
p <- graph_delta_area(x)
km.3 <- x[, , "HC_Euclidean", "3", drop = FALSE]
cm <- consensus_matrix(km.3)
dim(cm)
hm <- graph_heatmap(km.3)
library(datasets)
head(iris)
library(ggplot2)
ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) + geom_point()
iris[, -5]
irisCluster <- kmeans(iris[, -5], 3, nstart = 20)
irisCluster
table(irisCluster$cluster, iris$Species)
irisCluster$cluster <- as.factor(irisCluster$cluster)
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster)) + geom_point()
library(diceR)
library(ggplot2)
dat <- iris[, -5]
head(iris)
head(dat)
x <- consensus_cluster(dat, nk = 3:4, reps = 10, algorithms = c("km","pam","diana"),
progress = FALSE)
ccomb_matrix <- consensus_combine(x, element = "matrix")
str(ccomb_matrix, max.level = 2)
ccomb_class <- consensus_combine(CC, element = "class")
ccomb_class <- consensus_combine(x, element = "class")
ccomb_class
# consensus matrix across subsamples and algorithms and k
cm_all <- consensus_matrix(ccomb_class)
cm_all
x
ccomp <- consensus_evaluate(dat, x, plot = FALSE)
ccomp
knitr::kable(ccomp$indices$ii$`4`)
knitr::kable(ccomp$$ii$`4`)
knitr::kable(ccomp$ii$`4`)
ccomp
library(diceR)
library(ggplot2)
dat <- iris[, -5]
head(iris)
head(dat)
x <- consensus_cluster(dat, nk = 3:4, reps = 10, algorithms = c("km","pam","diana"),
progress = FALSE)
ccomb_matrix <- consensus_combine(x, element = "matrix")
ccomb_class <- consensus_combine(x, element = "class")
str(ccomb_matrix, max.level = 2)
options(max.print=1000000)
# consensus matrix across subsamples and algorithms and k
cm_all <- consensus_matrix(ccomb_class)
ccomp <- consensus_evaluate(dat, x, plot = FALSE)
ccomp
knitr::kable(ccomp$ii$`4`)
ccomb_matrix <- consensus_combine(x, element = "matrix")
ccomb_matrix
ccomb_class <- consensus_combine(x, element = "class")
ccomb_class
ccomp <- consensus_evaluate(dat, x, plot = FALSE)
knitr::kable(ccomp$ii$`4`)
cspaData <- CSPA(x, k = 3)
cspaData
table(mvData, iris$Species)
table(cspaData, iris$Species)
cspaData <- CSPA(x, k = 4)
table(cspaData, iris$Species)
cspaData <- CSPA(x, k = 3)
table(cspaData, iris$Species)
mvData <- majority_voting(x,is.relabelled = FALSE)
table(mvData, iris$Species)
irisClusterCSPA <- as.factor(cspaData)
irisClusterMV <- as.factor(mvData)
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisClusterCSPA)) + geom_point()
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisClusterMV)) + geom_point()
x <- consensus_cluster(dat, nk = 3:4, reps = 10, algorithms = c("km","pam","diana","hdbscan"),
progress = FALSE)
ccomb_matrix <- consensus_combine(x, element = "matrix")
ccomb_class <- consensus_combine(x, element = "class")
str(ccomb_matrix, max.level = 2)
x <- consensus_cluster(dat, nk = 3:4, reps = 10, algorithms = c("km","pam","diana","hdbscan"),
progress = FALSE)
ccomb_matrix <- consensus_combine(x, element = "matrix")
ccomb_class <- consensus_combine(x, element = "class")
str(ccomb_matrix, max.level = 2)
x <- consensus_cluster(dat, nk = 3:4, reps = 10, algorithms = c("km","pam","diana","cmeans"),
progress = FALSE)
ccomb_matrix <- consensus_combine(x, element = "matrix")
ccomb_class <- consensus_combine(x, element = "class")
str(ccomb_matrix, max.level = 2)
options(max.print=1000000)
# consensus matrix across subsamples and algorithms and k
cm_all <- consensus_matrix(ccomb_class)
ccomp <- consensus_evaluate(dat, x, plot = FALSE)
knitr::kable(ccomp$ii$`4`)
cspaData <- CSPA(x, k = 3)
table(cspaData, iris$Species)
mvData <- majority_voting(x,is.relabelled = FALSE)
table(mvData, iris$Species)
ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) + geom_point()
x <- consensus_cluster(dat, nk = 3:4, reps = 10, algorithms = c("km","pam","diana","cmeans","hc"),
progress = FALSE)
ccomb_matrix <- consensus_combine(x, element = "matrix")
ccomb_class <- consensus_combine(x, element = "class")
str(ccomb_matrix, max.level = 2)
options(max.print=1000000)
# consensus matrix across subsamples and algorithms and k
cm_all <- consensus_matrix(ccomb_class)
ccomp <- consensus_evaluate(dat, x, plot = FALSE)
knitr::kable(ccomp$ii$`4`)
cspaData <- CSPA(x, k = 3)
table(cspaData, iris$Species)
mvData <- majority_voting(x,is.relabelled = FALSE)
table(mvData, iris$Species)
x <- consensus_cluster(dat, nk = 3:4, reps = 10, algorithms = c("km","pam","diana","cmeans","hc","block"),
progress = FALSE)
ccomb_matrix <- consensus_combine(x, element = "matrix")
ccomb_class <- consensus_combine(x, element = "class")
str(ccomb_matrix, max.level = 2)
ccomp <- consensus_evaluate(dat, x, plot = FALSE)
knitr::kable(ccomp$ii$`4`)
cspaData <- CSPA(x, k = 3)
table(cspaData, iris$Species)
mvData <- majority_voting(x,is.relabelled = FALSE)
table(mvData, iris$Species)
ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) + geom_point()
library(diceR)
library(ggplot2)
dat <- iris[, -5]
head(iris)
head(dat)
x <- consensus_cluster(dat, nk = 3:4, reps = 10, algorithms = c("km","pam","diana"),
progress = FALSE)
ccomb_matrix <- consensus_combine(x, element = "matrix")
ccomb_class <- consensus_combine(x, element = "class")
str(ccomb_matrix, max.level = 2)
options(max.print=1000000)
# consensus matrix across subsamples and algorithms and k
cm_all <- consensus_matrix(ccomb_class)
ccomp <- consensus_evaluate(dat, x, plot = FALSE)
knitr::kable(ccomp$ii$`4`)
cspaData <- CSPA(x, k = 3)
table(cspaData, iris$Species)
mvData <- majority_voting(x,is.relabelled = FALSE)
table(mvData, iris$Species)
irisClusterCSPA <- as.factor(cspaData)
irisClusterMV <- as.factor(mvData)
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisClusterCSPA)) + geom_point()
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisClusterMV)) + geom_point()
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisClusterCSPA)) + geom_point()
