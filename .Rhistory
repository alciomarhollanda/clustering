sDb <- silhouette(db$cluster,
dist(iris[,-5]))
plot(sDb)
plot(db,d)
f <- fanny(iris[,-5],3,metric='euclidean',stand=T)
head(f$membership)
table(f$clustering,iris$Species)
sF <- silhouette(f$cluster,
dist(iris[,-5]))
mean(sF[,3])
clusplot(f)
plot(sF)
library(cluster)
d <- dist(scale(iris[,-5]))
methds <- c('kmeans','fanny','pam')
avgS <- matrix(NA,ncol=3,nrow=5,
dimnames=list(2:6,methds))
for(k in 2:6)
for(m in seq_along(methds)) {
if(m == 1){
c <- kmeans(d,centers=k,iter.max=200)
}else if( m == 2){
c <- fanny(d,k,metric='euclidean',stand=T)
}else if(m == 3){
c <- pam(d,k=k)
}
s <- silhouette(c$cluster,d)
avgS[k-1,m] <- mean(s[,3])
}
library(reshape2)
dt <- melt(avgS)
colnames(dt) <- c("NClusts","Meth","AvgS")
library(ggplot2)
ggplot(dt,aes(x=NClusts,y=AvgS,color=Meth)) +
geom_line()
library(cluster)
data(ruspini)
pr4 <- pam(ruspini, 4)
str(si <- silhouette(pr4))
(ssi <- summary(si))
plot(si) # silhouette plot
plot(si, col = c("red", "green", "blue", "purple"))# with cluster-wise coloring
si2 <- silhouette(pr4$clustering, dist(ruspini, "canberra"))
summary(si2) # has small values: "canberra"'s fault
plot(si2, nmax= 80, cex.names=0.6)
op <- par(mfrow= c(3,2), oma= c(0,0, 3, 0),
mgp= c(1.6,.8,0), mar= .1+c(4,2,2,2))
for(k in 2:6)
plot(silhouette(pam(ruspini, k=k)), main = paste("k = ",k), do.n.k=FALSE)
mtext("PAM(Ruspini) as in Kaufman & Rousseeuw, p.101",
outer = TRUE, font = par("font.main"), cex = par("cex.main")); frame()
## the same with cluster-wise colours:
c6 <- c("tomato", "forest green", "dark blue", "purple2", "goldenrod4", "gray20")
for(k in 2:6)
plot(silhouette(pam(ruspini, k=k)), main = paste("k = ",k), do.n.k=FALSE,
col = c6[1:k])
par(op)
## clara(): standard silhouette is just for the best random subset
data(xclara)
set.seed(7)
str(xc1k <- xclara[ sample(nrow(xclara), size = 1000) ,]) # rownames == indices
cl3 <- clara(xc1k, 3)
plot(silhouette(cl3))# only of the "best" subset of 46
## The full silhouette: internally needs large (36 MB) dist object:
sf <- silhouette(cl3, full = TRUE) ## this is the same as
s.full <- silhouette(cl3$clustering, daisy(xc1k))
stopifnot(all.equal(sf, s.full, check.attributes = FALSE, tolerance = 0))
## color dependent on original "3 groups of each 1000": % __FIXME ??__
plot(sf, col = 2+ as.integer(names(cl3$clustering) ) %/% 1000,
main ="plot(silhouette(clara(.), full = TRUE))")
## Silhouette for a hierarchical clustering:
ar <- agnes(ruspini)
si3 <- silhouette(cutree(ar, k = 5), # k = 4 gave the same as pam() above
daisy(ruspini))
plot(si3, nmax = 80, cex.names = 0.5)
## 2 groups: Agnes() wasn't too good:
si4 <- silhouette(cutree(ar, k = 2), daisy(ruspini))
plot(si4, nmax = 80, cex.names = 0.5)
library(diceR)
library(dplyr)
library(diceR)
library(dplyr)
library(ggplot2)
library(pander)
data(hgsc)
hgsc <- hgsc[1:100, 1:50]
#agrupar os hgscdados em 3 ou 4 clusters, usando 80% de reimampling em 5 repeti??es,
#para esses algoritmos de cluster: Hierarchical Clustering, PAM e DIvisive
#ANAlysis Clustering (DIANA).
#A dist?ncia euclidiana ? utilizada para todos os algoritmos.
CC <- consensus_cluster(hgsc, nk = 3:4, p.item = 1, reps = 5,
algorithms = c("hc", "pam", "diana"))
co <- capture.output(str(CC))
co
strwrap(co, width = 80)
strwrap(co, width = 100)
co
co <- capture.output(str(CC))
strwrap(co, width = 100)
CC <- apply(CC, 2:4, impute_knn, data = hgsc, seed = 1)
# Filtra somente PAM_Euclidean 4
pam.4 <- CC[, , "PAM_Euclidean", "4", drop = FALSE]
cm <- consensus_matrix(pam.4)
pam.4
cm <- consensus_matrix(pam.4)
dim(cm)
hm <- graph_heatmap(pam.4)
dev.off()
hm <- graph_heatmap(pam.4)
hm <- graph_heatmap(pam.4)
hm <- graph_heatmap(pam.4)
strwrap(co, width = 80)
CC <- apply(CC, 2:4, impute_knn, data = hgsc, seed = 1)
# Filtra somente PAM_Euclidean 4
pam.4 <- CC[, , "PAM_Euclidean", "4", drop = FALSE]
cm <- consensus_matrix(pam.4)
dim(cm)
dev.off()
hm <- graph_heatmap(pam.4)
#agrupar os hgscdados em 3 ou 4 clusters, usando 80% de reimampling em 5 repeti??es,
#para esses algoritmos de cluster: Hierarchical Clustering, PAM e DIvisive
#ANAlysis Clustering (DIANA).
#A dist?ncia euclidiana ? utilizada para todos os algoritmos.
CC <- consensus_cluster(hgsc, nk = 3:4, p.item = 0.8, reps = 5,
algorithms = c("hc", "pam", "diana"))
co <- capture.output(str(CC))
strwrap(co, width = 80)
CC <- apply(CC, 2:4, impute_knn, data = hgsc, seed = 1)
# Filtra somente PAM_Euclidean 4
pam.4 <- CC[, , "PAM_Euclidean", "4", drop = FALSE]
cm <- consensus_matrix(pam.4)
dim(cm)
dev.off()
hm <- graph_heatmap(pam.4)
ccomb_matrix <- consensus_combine(CC, element = "matrix")
str(ccomb_matrix, max.level = 2)
str(ccomb_matrix, max.level  = 5)
ccomb_matrix
View(ccomb_matrix)
ccomb_matrix[["3"]][["HC_Euclidean"]]
CC
options(max.print=999999)
getOption("max.print")
options(max.print = .Machine$integer.max)
bigger = options()$max.print + 200  # or add something larger
options("max.print" = bigger) # apparently RStudio sets max.print very low.
bigger = options()$max.print  # or add something larger
options("max.print" = bigger) # apparently RStudio sets max.print very low.
CC
str(ccomb_matrix, max.level  = 5)
ccomb_matrix <- consensus_combine(CC, element = "matrix")
str(ccomb_matrix, max.level  = 5)
ccomb_class <- consensus_combine(CC, element = "class")
ccomb_class
cm_k3 <- consensus_matrix(ccomb_class$`3`)
cm_k3
cm_k4 <- consensus_matrix(ccomb_class$`4`)
cm_k4
View(cm_k4)
View(cm_k3)
# consensus matrix across subsamples and algorithms and k
cm_all <- consensus_matrix(ccomb_class)
cm_all
View(cm_all)
View(cm_k3)
CC2 <- consensus_cluster(hgsc, nk = 3:4, p.item = 0.8, reps = 5,
algorithms = "km")
ccomb_class2 <- consensus_combine(CC, CC2, element = "class")
ccomb_class2
ccomp <- consensus_evaluate(hgsc, CC, CC2, plot = FALSE)
ccomp
ctrim <- consensus_evaluate(hgsc, CC, CC2, trim = TRUE, reweigh = FALSE, n = 2)
ctrim
library(datasets)
head(iris)
library(ggplot2)
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
set.seed(20)
irisCluster <- kmeans(iris[, 3:4], 3, nstart = 20)
irisCluster
table(irisCluster$cluster, iris$Species)
irisCluster$cluster <- as.factor(irisCluster$cluster)
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster)) + geom_point()
library(datasets)
head(iris)
library(ggplot2)
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
library(ggplot2)
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
library(datasets)
head(iris)
ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) + geom_point()
library(ggplot2)
ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) + geom_point()
library(datasets)
head(iris)
library(ggplot2)
set.seed(20)
irisCluster <- kmeans(iris[, 3:4], 3, nstart = 20)
irisCluster
table(irisCluster$cluster, iris$Species)
irisCluster$cluster <- as.factor(irisCluster$cluster)
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster)) + geom_point()
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster)) + geom_point()
irisCluster
irisCluster$cluster
data(hgsc)
library(diceR)
library(diceR)
library(dplyr)
library(ggplot2)
library(pander)
data(hgsc)
library(dplyr)
library(diceR)
library(dplyr)
library(ggplot2)
library(pander)
data(hgsc)
dat <- hgsc[1:100, 1:50]
x <- consensus_cluster(dat, nk = 4, reps = 4, algorithms = c("hc", "diana"),
progress = FALSE)
x
CSPA(x, k = 4)
# Consensus clustering for 3 algorithms
library(ggplot2)
set.seed(911)
x <- matrix(rnorm(80), ncol = 10)
x
CC1 <- consensus_cluster(x, nk = 2:4, reps = 3,
algorithms = c("hc", "pam", "km"), progress = FALSE)
CC1
# Plot CDF
p <- graph_cdf(CC1)
# Change y label and add colours
p + labs(y = "Probability") + stat_ecdf(aes(colour = k)) +
scale_color_brewer(palette = "Set2")
# Delta Area
p <- graph_delta_area(CC1)
# Heatmaps with column side colours corresponding to clusters
CC2 <- consensus_cluster(x, nk = 3, reps = 3, algorithms = "hc", progress =
FALSE)
graph_heatmap(CC2)
# Track how cluster assignments change between algorithms
p <- graph_tracking(CC1)
data(hgsc)
dat <- hgsc[1:100, 1:50]
cc <- consensus_cluster(dat, nk = 4, reps = 6, algorithms = "pam", progress =
FALSE)
table(majority_voting(cc[, , 1, 1, drop = FALSE], is.relabelled = FALSE))
cc
cc[, , 1, 1, drop = FALSE]
library(diceR)
library(dplyr)
library(ggplot2)
library(pander)
data(hgsc)
hgsc <- hgsc[1:100, 1:50]
#agrupar os hgscdados em 3 ou 4 clusters, usando 80% de reimampling em 5 repeti??es,
#para esses algoritmos de cluster: Hierarchical Clustering, PAM e DIvisive
#ANAlysis Clustering (DIANA).
#A dist?ncia euclidiana ? utilizada para todos os algoritmos.
CC <- consensus_cluster(hgsc, nk = 3:4, p.item = 0.8, reps = 5,
algorithms = c("hc", "pam", "diana"))
co <- capture.output(str(CC))
strwrap(co, width = 80)
CC <- apply(CC, 2:4, impute_knn, data = hgsc, seed = 1)
bigger = options()$max.print  # or add something larger
options("max.print" = bigger) # apparently RStudio sets max.print very low.
CC
# Filtra somente PAM_Euclidean 4
pam.4 <- CC[, , "PAM_Euclidean", "4", drop = FALSE]
cm <- consensus_matrix(pam.4)
dim(cm)
hm <- graph_heatmap(pam.4)
ccomb_matrix <- consensus_combine(CC, element = "matrix")
ccomb_class <- consensus_combine(CC, element = "class")
ccomb_class
ccomb_matrix
str(ccomb_matrix, max.level  = 5)
ccomb_class
cm_k3 <- consensus_matrix(ccomb_class$`3`)
cm_k3
library(diceR)
dat <- iris[, -5]
dice.obj <- dice(dat, nk = 4, reps = 5, algorithms = "km", cons.funs = "kmodes")
str(dice.obj, max.level = 2)
dice.obj
knitr::kable(head(dice.obj$clusters))
kable(head(dice.obj$clusters))
(head(dice.obj$clusters))
dice.obj$clusters
library(diceR)
data(hgsc)
library(diceR)
dat <- iris[, -5]
dice.obj <- dice(dat, nk = 4, reps = 5, algorithms = "km", cons.funs = c("majority","CSPA"))
str(dice.obj, max.level = 2)
knitr::kable(head(obj$clusters))
knitr::kable(head(dice.obj$clusters))
dice.obj
irisObj <- dice(dat, nk = 4, reps = 5, algorithms = c("km","pam"), cons.funs = c("majority","CSPA"))
knitr::kable(head(irisObj$clusters))
irisObj$clusters
irisObj
knitr::kable(head(irisObj$clusters))
irisObj$clusters
library(diceR)
dat <- iris[, -5]
x <- consensus_cluster(dat, nk = 4, reps = 4, algorithms = c("hc", "diana"),
progress = FALSE)
CSPA(x, k = 4)
x
CSPA(x, k = 3)
CSPA(x, k = 4)
library(datasets)
head(iris)
library(ggplot2)
ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) + geom_point()
iris$Species
set.seed(20)
irisCluster <- kmeans(iris[, 3:4], 3, nstart = 20)
irisCluster
table(irisCluster$cluster, iris$Species)
irisCluster$cluster <- as.factor(irisCluster$cluster)
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster)) + geom_point()
library(diceR)
dat <- iris[, -5]
head(iris)
head(dat)
library(ggplot2)
library(diceR)
library(ggplot2)
dat <- iris[, -5]
head(iris)
head(dat)
knitr::kable(head(irisObj$clusters))
x <- consensus_cluster(dat, nk = 4, reps = 4, algorithms = c("hc", "diana"),
progress = FALSE)
CSPA(x, k = 4)
knitr::kable(head(x$clusters))
cspaData <- CSPA(x, k = 4)
cspaData
knitr::kable(head(cspaData))
ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) + geom_point()
table(cspaData, iris$Species)
irisCluster$cluster <- as.factor(cspaData)
irisCluster <- as.factor(cspaData)
irisCluster
cspaData
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster)) + geom_point()
x <- consensus_cluster(dat, nk = 4, reps = 4, algorithms = c("hc", "diana","km"),
progress = FALSE)
cspaData <- CSPA(x, k = 4)
ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) + geom_point()
set.seed(20)
table(cspaData, iris$Species)
ggplot(iris, aes(Petal.Length, Petal.Width, color = cspaData)) + geom_point()
irisCluster <- as.factor(cspaData)
ggplot(iris, aes(Petal.Length, Petal.Width, color = cspaData)) + geom_point()
irisCluster <- as.factor(cspaData)
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster)) + geom_point()
x <- consensus_cluster(dat, nk = 4, reps = 4, algorithms = c("hc", "diana","km","hdbscan"),
progress = FALSE)
x
cspaData <- CSPA(x, k = 4)
ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) + geom_point()
table(cspaData, iris$Species)
irisCluster <- as.factor(cspaData)
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster)) + geom_point()
mvData <- majority_voting(x, k = 4)
mvData <- majority_voting(x,is.relabelled = FALSE)
mvData
table(mvData, iris$Species)
table(cspaData, iris$Species)
irisClusterCSPA <- as.factor(cspaData)
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisClusterCSPA)) + geom_point()
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisClusterMV)) + geom_point()
irisClusterMV <- as.factor(mvData)
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisClusterMV)) + geom_point()
library(diceR)
library(ggplot2)
dat <- iris[, -5]
head(iris)
head(dat)
x <- consensus_cluster(dat, nk = 4, reps = 4, algorithms = c("km"),
progress = FALSE)
x
x$cluster
x
cspaData <- CSPA(x, k = 4)
mvData <- majority_voting(x,is.relabelled = FALSE)
ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) + geom_point()
table(cspaData, iris$Species)
x <- consensus_cluster(dat, nk = 3, reps = 4, algorithms = c("km"),
progress = FALSE)
cspaData <- CSPA(x, k = 4)
cspaData <- CSPA(x, k = 3)
mvData <- majority_voting(x,is.relabelled = FALSE)
ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) + geom_point()
table(cspaData, iris$Species)
table(mvData, iris$Species)
irisClusterCSPA <- as.factor(cspaData)
irisClusterMV <- as.factor(mvData)
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisClusterCSPA)) + geom_point()
set.seed(20)
irisCluster <- kmeans(iris[, 3:4], 3, nstart = 20)
irisCluster
table(irisCluster$cluster, iris$Species)
irisCluster$cluster <- as.factor(irisCluster$cluster)
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster)) + geom_point()
set.seed(20)
x <- consensus_cluster(dat, nk = 3, reps = 4, algorithms = c("km"),
progress = FALSE)
cspaData <- CSPA(x, k = 3)
mvData <- majority_voting(x,is.relabelled = FALSE)
ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) + geom_point()
table(cspaData, iris$Species)
table(mvData, iris$Species)
irisClusterMV <- as.factor(mvData)
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisClusterCSPA)) + geom_point()
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisClusterMV)) + geom_point()
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster)) + geom_point()
table(irisCluster$cluster, iris$Species)
set.seed(20)
x <- consensus_cluster(dat, nk = 3, reps = 1, algorithms = c("km"),
progress = FALSE)
x
table(x, iris$Species)
cspaData <- CSPA(x, k = 3)
mvData <- majority_voting(x,is.relabelled = FALSE)
table(cspaData, iris$Species)
set.seed(20)
x <- consensus_cluster(dat, nk = 3, reps = 1, algorithms = c("km"),
progress = FALSE)
table(x, iris$Species)
set.seed(20)
x <- consensus_cluster(dat, nk = 3, reps = 10, algorithms = c("km"),
progress = FALSE)
table(x, iris$Species)
x
cspaData <- CSPA(x, k = 3)
mvData <- majority_voting(x,is.relabelled = FALSE)
table(x, iris$Species)
cspaData <- CSPA(x, k = 3)
mvData <- majority_voting(x,is.relabelled = FALSE)
mvData
table(cspaData, iris$Species)
table(mvData, iris$Species)
x <- consensus_cluster(dat, nk = 3, reps = 20, algorithms = c("km"),
progress = FALSE)
cspaData <- CSPA(x, k = 3)
mvData <- majority_voting(x,is.relabelled = FALSE)
table(cspaData, iris$Species)
table(mvData, iris$Species)
set.seed(20)
irisCluster <- kmeans(iris[, 3:4], 3, nstart = 20)
table(irisCluster$cluster, iris$Species)
library(datasets)
head(iris)
library(ggplot2)
ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) + geom_point()
set.seed(20)
irisCluster <- kmeans(iris[, 3:4], 3, nstart = 20)
irisCluster
table(irisCluster$cluster, iris$Species)
library(datasets)
head(iris)
library(ggplot2)
ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) + geom_point()
set.seed(20)
irisCluster <- kmeans(iris[, 3:4], 3, nstart = 20)
table(irisCluster$cluster, iris$Species)
irisCluster$cluster <- as.factor(irisCluster$cluster)
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster)) + geom_point()
library(diceR)
library(ggplot2)
dat <- iris[, -5]
head(iris)
head(dat)
set.seed(20)
x <- consensus_cluster(dat, nk = 3, reps = 20, algorithms = c("km"),
progress = FALSE)
cspaData <- CSPA(x, k = 3)
mvData <- majority_voting(x,is.relabelled = FALSE)
ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) + geom_point()
table(cspaData, iris$Species)
table(mvData, iris$Species)
library(ggplot2)
set.seed(20)
irisCluster <- kmeans(iris[, 3:4], 3, nstart = 20)
table(irisCluster$cluster, iris$Species)
set.seed(20)
x <- consensus_cluster(dat, nk = 3, reps = 20, algorithms = c("km"),
progress = FALSE)
kmodeData = <- k_modes(x,is.relabelled = false,seed = 20)
kmodeData <- k_modes(x,is.relabelled = false,seed = 20)
kmodeData <- k_modes(x,is.relabelled = FALSE,seed = 20)
kmodeData
table(kmodeData, iris$Species)
table(mvData, iris$Species)
table(cspaData, iris$Species)
library(datasets)
head(iris)
library(ggplot2)
ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) + geom_point()
set.seed(20)
irisCluster <- kmeans(iris[, 3:4], 3, nstart = 20)
irisCluster
table(irisCluster$cluster, iris$Species)
